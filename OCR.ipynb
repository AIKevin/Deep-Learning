{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCR.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIKevin/Deep-Learning/blob/master/OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2lUN7Fi3zdZw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YbxAtpM-HH15",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class OCRModel:\n",
        "  \n",
        "  def __init__(self, hpm):\n",
        "    self.hpm = hpm\n",
        "    self.graph = tf.Graph()\n",
        "    self.step = tf.train.global_step()\n",
        "  \n",
        "  def add_vgg(self, sess, meta_path, check_path):\n",
        "    with self.graph.as_default():\n",
        "      saver = tf.train.import_meta_graph(meta_path)\n",
        "      with tf.Session() as sess:\n",
        "        saver.restore(sess, tf.train.latest_checkpoint(check_path))\n",
        "       \n",
        "      self.input = self.graph.get_tensor_by_name('input:0')\n",
        "      vgg_out = self.graph.get_tensor_by_name('pool5:0')\n",
        "      self.vgg_out = tf.stop_gradient(vgg_out)\n",
        "      \n",
        "      \n",
        "  def get_graph(self):\n",
        "    return self.graph\n",
        "  \n",
        "  \n",
        "  def add_placeholders(self):\n",
        "    \n",
        "    with self.graph.as_default():\n",
        "      self.keep_prob = tf.placeholder(dtype = tf.float32)\n",
        "      self.target = tf.placeholder(dtype=tf.int32, shape=[self.hpm['batch_size']])\n",
        "      \n",
        "  def add_fully_connected(self):\n",
        "    \n",
        "    with self.graph.as_default():\n",
        "      fc_in = tf.reshape(self.vgg_out, [-1, 512], name='fc_in' )\n",
        "\n",
        "      fc1_w = tf.get_variable(shape=[512, 124], dtype=tf.float32, name=\"fc1_w\")\n",
        "      fc1_b = tf.get_variable(shape=[124], dtype=tf.float32, name='fc1_b')\n",
        "      fc1 = tf.identity(tf.matmul(fc_in, fc1_w) + fc1_b, 'fc1')\n",
        "\n",
        "      dropout = tf.nn.dropout(fc1, self.keep_prob)\n",
        "\n",
        "      fc2_w = tf.get_variable(shape=[124, self.hpm['output_num']], dtype=tf.float32, name=\"fc2_w\")\n",
        "      fc2_b = tf.get_variable(shape=[self.hpm['output_num']], dtype=tf.float32, name='fc2_b')\n",
        "      fc2 = tf.identity((tf.matmul(dropout, fc2_w) + fc2_b), 'fc2')\n",
        "\n",
        "      self.output = fc2\n",
        "      \n",
        "  def add_loss(self):\n",
        "    with self.graph.as_default():\n",
        "      target = tf.one_hot(self.target, depth = self.hpm['output_num'])\n",
        "      self.loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels = target, logits = self.output, name=\"soft_cross_entropy\")\n",
        "    \n",
        "  def add_train_op(self):\n",
        "    with self.graph.as_default():\n",
        "      adam = tf.train.AdamOptimizer()\n",
        "      self.optimize = adam.minimize(self.loss, global_step = self.step)\n",
        "    \n",
        "  def add_decode_op(self):\n",
        "    with self.graph.as_default():\n",
        "      self.decoded_output = tf.argmax(tf.nn.softmax(self.output), axis=-1)\n",
        "    \n",
        "  def set_session(self, sess):\n",
        "    self.sess = sess\n",
        "    \n",
        "  def _generator(self):\n",
        "    feats = np.random.normal(0, 1, self.hpm['batch_size'])\n",
        "    labels = np.random.normal(0, 1, self.hpm['batch_size'])\n",
        "    yield feats, labels\n",
        "  \n",
        "  def dataread(self, data_path):\n",
        "    data= pd.read_csv(data_path).values\n",
        "    labels=data[:,0]\n",
        "    features= data[:,1:]\n",
        "    features= tf.reshape(features, (hpm['input_size'],hpm['input_size']), name= 'batch_inp')\n",
        "    return features, labels\n",
        "    \n",
        "  def batcher(self, dataset):\n",
        "    shapes= (self.hpm['batch_size'],hpm['input_size'])\n",
        "    dataset = tf.data.Dataset.from_generator(generator=_generator,\n",
        "                                             output_types=(tf.float32, tf.float32),\n",
        "                                             output_shapes=shapes)\n",
        "    dataset = dataset.batch(self.hpm['batch_size'])\n",
        "    dataset = dataset.repeat(self.hpm['num_epochs'])\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    features_tensors, labels = iterator.get_next()\n",
        "    return features_tensors, labels\n",
        "  \n",
        "  def make_feed_dict(self, batch):\n",
        "    feed_dict = {}\n",
        "\n",
        "    feed_dict[x] = batch[0]\n",
        "    feed_dict[y]= batch[1]\n",
        "   \n",
        "\n",
        "    return feed_dict\n",
        "  \n",
        "  \n",
        "  def train(self, batch):\n",
        "    with self.graph.as_default():\n",
        "      to_feed = self.make_feed_dict(batch)\n",
        "      to_return = {'train_op': self.optimize,\n",
        "                   'loss' : self.loss,\n",
        "                   'global_step' : self.step}\n",
        "      \n",
        "      return self.sess.run(to_return, to_feed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UrRNUfp0oSdF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.Session(config=config, ...)\n",
        "\n",
        "def get_config():\n",
        "  config = tf.ConfigProto()\n",
        "  config.gpu_options.allow_growth = True\n",
        "  config.allow_soft_placement = True\n",
        "  return config\n",
        "\n",
        "def run_training(model, batcher, hpm, training_steps, check_dir):\n",
        "  \n",
        "  with tf.train.MonitoredTrainingSession(checkpoint_dir  = checkdir,\n",
        "                                        hooks = [tf.train.StopAtStepHook(last_step=training_steps)],\n",
        "                                        save_summaries_steps = None, save_summaries_secs= None,\n",
        "                                        save_checkpoint_steps=4, scaffold=tf.train.Scaffold(saver=tf.train.Saver(max_to_keep=3)),\n",
        "                                        config = get_config()) as sess:\n",
        "    model.set_session(sess)\n",
        "    while not sess.should_stop():\n",
        "      step = tf.train.global_step(sess, model.step)\n",
        "      tf.logging.info('Starting training model on a batch ...')\n",
        "      t0 = time.time()\n",
        "      batch = batcher.next()      \n",
        "      results=model.train(batch)\n",
        "      t1=time.time()\n",
        "      tf.logging.info('seconds for step %d : %.3f', results['global_step'],t1-t0)\n",
        "      \n",
        "      loss=results['loss']\n",
        "      \n",
        "      tf.logging.info(\"loss : %f\", loss)\n",
        "      \n",
        "def restore_model(sess, hpm, path=None):\n",
        "    saver = tf.train.Saver()\n",
        "    try:\n",
        "      if path:\n",
        "        saver.restore(sess, path)\n",
        "        return True\n",
        "      else:\n",
        "        saver.restore(s, tf.train.latest_checkpoint(path))\n",
        "        return True\n",
        "    except:\n",
        "      tf.logging.warning(\"Error restoring model\")\n",
        "      return False\n",
        "      \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pfTSNH8LJKkM",
        "colab_type": "code",
        "outputId": "119dbc07-c684-4785-9417-dbf5a21d495c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "model = OCRModel()\n",
        "s = tf.Session(graph=model.get_graph())\n",
        "model.add_vgg(s, '/content/gdrive/My Drive/OCR/checkpoints/model.ckpt.meta', '/content/gdrive/My Drive/OCR/checkpoints')\n",
        "model.add_placeholders()\n",
        "model.add_fully_connected()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/OCR/checkpoints/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W9h7oSMAVUWC",
        "colab_type": "code",
        "outputId": "6a79f570-2262-4e39-8b93-2ea7e0390674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'input:0' shape=(?, 32, 32, 3) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "TEXK_0e4ChiV",
        "colab_type": "code",
        "outputId": "b3fda8eb-9a6b-4029-b38e-307f29aaf82f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "a = np.random.randn(10,32,32,3)\n",
        "a = a.astype(np.float32)\n",
        "\n",
        "with tf.Session(graph=model.get_graph())  as s:\n",
        "  s.run(tf.global_variables_initializer())\n",
        "  print(np.shape(s.run(model.output, {model.input:a, model.keep_prob:0.5})))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 62)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lXPbp0U9zo15",
        "colab_type": "code",
        "outputId": "56b4c4ae-36f7-4145-aa1c-cbb15885508d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QeyHJUBD13pR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3XMR6rW81i6u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def f1(dest):\n",
        "\n",
        "    total = 0\n",
        "    for root, dirs, files in os.walk(dest):\n",
        "      prin(root)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F_hlj5wV2IOq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f1(\"/content/gdrive/My drive/OCR/by_class.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hVrelYMr2yKt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data= pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/emnist-byclass-train.csv\").values\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qXlZfkRKgrUh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y=data[:,0]\n",
        "x= data[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}